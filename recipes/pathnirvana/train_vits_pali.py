import os

from trainer import Trainer, TrainerArgs

from TTS.tts.configs.shared_configs import BaseDatasetConfig, CharactersConfig
from TTS.tts.configs.vits_config import VitsConfig
from TTS.tts.datasets import load_tts_samples
from TTS.tts.models.vits import Vits, VitsAudioConfig
from TTS.tts.utils.text.tokenizer import TTSTokenizer
from TTS.utils.audio import AudioProcessor

output_path = os.path.dirname(os.path.abspath(__file__))
dataset_config = BaseDatasetConfig(
    formatter="pathnirvana_mettananda", meta_file_train="metadata_shuf.csv", path=os.path.join(output_path, "pali_dataset/")
)
audio_config = VitsAudioConfig(
    sample_rate=22050, 
    win_length=1024, # can reduce
    hop_length=256, # can not change
    num_mels=80, # can increase
    mel_fmin=0, #  50 recommended for male voices
    mel_fmax=None # has to be less than half of sample rate
)
# audio_config = VitsAudioConfig( # used for training (4)
#     sample_rate=22050, 
#     win_length=768,
#     hop_length=256, 
#     num_mels=128, # increased from 80
#     mel_fmin=40,  # from 0 to 40
#     mel_fmax=11025 # has to be less than half of sample rate (was None)
# )

config = VitsConfig(
    audio=audio_config,
    run_name="vits_pali",
    batch_size=38,
    eval_batch_size=32,
    batch_group_size=5,
    num_loader_workers=8,
    num_eval_loader_workers=4,
    run_eval=True,
    test_delay_epochs=-1,
    epochs=1000,
    text_cleaner=None, # the text prompts were is already cleaned, remove extra whitespace, special symbols etc
    use_phonemes=False,
    #phoneme_language="en-us",
    #phoneme_cache_path=os.path.join(output_path, "phoneme_cache"),
    compute_input_seq_cache=True,
    max_audio_len=25 * 22050, # audio longer than this will be ignored
    add_blank=True, # this is by default true for vits, not sure if needed, speed is not changed by much
    characters=CharactersConfig(
        characters_class="TTS.tts.models.vits.VitsCharacters",
        pad="<PAD>",
        eos="<EOS>",
        bos="<BOS>",
        blank="<BLNK>",
        #characters=" !#'(),-.:;?x‡∂Ç‡∂Ö‡∂Ü‡∂â‡∂ä‡∂ã‡∂å‡∂ë‡∂î‡∂ö‡∂õ‡∂ú‡∂ù‡∂û‡∂†‡∂°‡∂¢‡∂£‡∂§‡∂ß‡∂®‡∂©‡∂™‡∂´‡∂≠‡∂Æ‡∂Ø‡∂∞‡∂±‡∂¥‡∂µ‡∂∂‡∂∑‡∂∏‡∂∫‡∂ª‡∂Ω‡∑Ä‡∑É‡∑Ñ‡∑Ö‡∑ä‡∑è‡∑í‡∑ì‡∑î‡∑ñ‡∑ô‡∑ú",
        characters=" '(),-.:;?abcdeghijklmnoprstuvxyz√±ƒÅƒ´≈´·∏ç·∏∑·πÉ·πÖ·πá·π≠",
        punctuations=" '(),-.:;?xz",
        phonemes=None,
        is_unique=True,
        is_sorted=True,
    ),
    test_sentences=[
        ["suppiyassa pana paribbƒÅjakassa antevƒÅsƒ´ brahmadatto mƒÅ·πáavo anekapariyƒÅyena buddhassa va·πá·πáa·πÉ bhƒÅsati, dhammassa va·πá·πáa·πÉ bhƒÅsati, sa·πÖghassa va·πá·πáa·πÉ bhƒÅsati."],
        ["namo tassa bhagavato arahato sammƒÅ sambuddhassa"],
        ["manopubba·πÖgamƒÅ dhammƒÅ manose·π≠·π≠hƒÅ manomayƒÅ x manasƒÅ ce padu·π≠·π≠hena bhƒÅsati vƒÅ karoti vƒÅ x tato na·πÉ dukkhamanveti, cakka·πÉ'va vahato pada·πÉ."],
        ["mƒÅlƒÅgandhavilepanadhƒÅra·πáama·πá·∏çanavibh≈´sana·π≠·π≠hƒÅnƒÅ verama·πáƒ´sikkhƒÅpada·πÉ samƒÅdiyƒÅmi."],
        ["sekhabalasa·πÖkhittasutta·πÉz"],
        ["yo brƒÅhma·πáo bƒÅhitapƒÅpadhammo x nihuhu·πÖko nikkasƒÅvo yatatto x vedantag≈´ vusitabrahmacariyo"],
        ["kittƒÅvatƒÅ saccƒÅna·πÉ saccapa√±√±atti: yƒÅvatƒÅ cattƒÅri saccƒÅni, dukkhasacca·πÉ samudayasacca·πÉ nirodhasacca·πÉ maggasacca·πÉ. ettƒÅvatƒÅ saccƒÅna·πÉ saccapa√±√±atti."],
        #["‡∑É‡∑î‡∂¥‡∑ä‡∂¥‡∑í‡∂∫‡∑É‡∑ä‡∑É ‡∂¥‡∂± ‡∂¥‡∂ª‡∑í‡∂∂‡∑ä‡∂∂‡∑è‡∂¢‡∂ö‡∑É‡∑ä‡∑É ‡∂Ö‡∂±‡∑ä‡∂≠‡∑ô‡∑Ä‡∑è‡∑É‡∑ì ‡∂∂‡∑ä‡∂ª‡∑Ñ‡∑ä‡∂∏‡∂Ø‡∂≠‡∑ä‡∂≠‡∑ú ‡∂∏‡∑è‡∂´‡∑Ä‡∑ú ‡∂Ö‡∂±‡∑ô‡∂ö‡∂¥‡∂ª‡∑í‡∂∫‡∑è‡∂∫‡∑ô‡∂± ‡∂∂‡∑î‡∂Ø‡∑ä‡∂∞‡∑É‡∑ä‡∑É ‡∑Ä‡∂´‡∑ä‡∂´‡∂Ç ‡∂∑‡∑è‡∑É‡∂≠‡∑í, ‡∂∞‡∂∏‡∑ä‡∂∏‡∑É‡∑ä‡∑É ‡∑Ä‡∂´‡∑ä‡∂´‡∂Ç ‡∂∑‡∑è‡∑É‡∂≠‡∑í, ‡∑É‡∂û‡∑ä‡∂ù‡∑É‡∑ä‡∑É ‡∑Ä‡∂´‡∑ä‡∂´‡∂Ç ‡∂∑‡∑è‡∑É‡∂≠‡∑í."],
        #["‡∂±‡∂∏‡∑ú ‡∂≠‡∑É‡∑ä‡∑É ‡∂∑‡∂ú‡∑Ä‡∂≠‡∑ú ‡∂Ö‡∂ª‡∑Ñ‡∂≠‡∑ú ‡∑É‡∂∏‡∑ä‡∂∏‡∑è ‡∑É‡∂∏‡∑ä‡∂∂‡∑î‡∂Ø‡∑ä‡∂∞‡∑É‡∑ä‡∑É"],
        #["‡∂∏‡∂±‡∑ú‡∂¥‡∑î‡∂∂‡∑ä‡∂∂‡∂û‡∑ä‡∂ú‡∂∏‡∑è ‡∂∞‡∂∏‡∑ä‡∂∏‡∑è ‡∂∏‡∂±‡∑ú‡∑É‡∑ô‡∂ß‡∑ä‡∂®‡∑è ‡∂∏‡∂±‡∑ú‡∂∏‡∂∫‡∑è x ‡∂∏‡∂±‡∑É‡∑è ‡∂†‡∑ô ‡∂¥‡∂Ø‡∑î‡∂ß‡∑ä‡∂®‡∑ô‡∂± ‡∂∑‡∑è‡∑É‡∂≠‡∑í ‡∑Ä‡∑è ‡∂ö‡∂ª‡∑ú‡∂≠‡∑í ‡∑Ä‡∑è x ‡∂≠‡∂≠‡∑ú ‡∂±‡∂Ç ‡∂Ø‡∑î‡∂ö‡∑ä‡∂õ‡∂∏‡∂±‡∑ä‡∑Ä‡∑ô‡∂≠‡∑í, ‡∂†‡∂ö‡∑ä‡∂ö‡∂Ç'‡∑Ä ‡∑Ä‡∑Ñ‡∂≠‡∑ú ‡∂¥‡∂Ø‡∂Ç."],
        #["‡∂∏‡∑è‡∂Ω‡∑è‡∂ú‡∂±‡∑ä‡∂∞‡∑Ä‡∑í‡∂Ω‡∑ô‡∂¥‡∂±‡∂∞‡∑è‡∂ª‡∂´‡∂∏‡∂´‡∑ä‡∂©‡∂±‡∑Ä‡∑í‡∂∑‡∑ñ‡∑É‡∂±‡∂ß‡∑ä‡∂®‡∑è‡∂±‡∑è ‡∑Ä‡∑ô‡∂ª‡∂∏‡∂´‡∑ì‡∑É‡∑í‡∂ö‡∑ä‡∂õ‡∑è‡∂¥‡∂Ø‡∂Ç ‡∑É‡∂∏‡∑è‡∂Ø‡∑í‡∂∫‡∑è‡∂∏‡∑í."],
        #["‡∑É‡∑ô‡∂õ‡∂∂‡∂Ω‡∑É‡∂û‡∑ä‡∂õ‡∑í‡∂≠‡∑ä‡∂≠‡∑É‡∑î‡∂≠‡∑ä‡∂≠‡∂Ç"],
        #["‡∂∫‡∑ú ‡∂∂‡∑ä‚Äç‡∂ª‡∑è‡∑Ñ‡∑ä‡∂∏‡∂´‡∑ú ‡∂∂‡∑è‡∑Ñ‡∑í‡∂≠‡∂¥‡∑è‡∂¥‡∂∞‡∂∏‡∑ä‡∂∏‡∑ú x ‡∂±‡∑í‡∑Ñ‡∑î‡∑Ñ‡∑î‡∂û‡∑ä‡∂ö‡∑ú ‡∂±‡∑í‡∂ö‡∑ä‡∂ö‡∑É‡∑è‡∑Ä‡∑ú ‡∂∫‡∂≠‡∂≠‡∑ä‡∂≠‡∑ú x ‡∑Ä‡∑ô‡∂Ø‡∂±‡∑ä‡∂≠‡∂ú‡∑ñ ‡∑Ä‡∑î‡∑É‡∑í‡∂≠‡∂∂‡∑ä‚Äç‡∂ª‡∑Ñ‡∑ä‡∂∏‡∂†‡∂ª‡∑í‡∂∫‡∑ú"],
        #["‡∂ö‡∑í‡∂≠‡∑ä‡∂≠‡∑è‡∑Ä‡∂≠‡∑è ‡∑É‡∂†‡∑ä‡∂†‡∑è‡∂±‡∂Ç ‡∑É‡∂†‡∑ä‡∂†‡∂¥‡∂§‡∑ä‡∂§‡∂≠‡∑ä‡∂≠‡∑í: ‡∂∫‡∑è‡∑Ä‡∂≠‡∑è ‡∂†‡∂≠‡∑ä‡∂≠‡∑è‡∂ª‡∑í ‡∑É‡∂†‡∑ä‡∂†‡∑è‡∂±‡∑í, ‡∂Ø‡∑î‡∂ö‡∑ä‡∂õ‡∑É‡∂†‡∑ä‡∂†‡∂Ç ‡∑É‡∂∏‡∑î‡∂Ø‡∂∫‡∑É‡∂†‡∑ä‡∂†‡∂Ç ‡∂±‡∑í‡∂ª‡∑ú‡∂∞‡∑É‡∂†‡∑ä‡∂†‡∂Ç ‡∂∏‡∂ú‡∑ä‡∂ú‡∑É‡∂†‡∑ä‡∂†‡∂Ç. ‡∂ë‡∂≠‡∑ä‡∂≠‡∑è‡∑Ä‡∂≠‡∑è ‡∑É‡∂†‡∑ä‡∂†‡∑è‡∂±‡∂Ç ‡∑É‡∂†‡∑ä‡∂†‡∂¥‡∂§‡∑ä‡∂§‡∂≠‡∑ä‡∂≠‡∑í."],
    ],
    print_step=100,
    print_eval=False,
    mixed_precision=True, # try with false since other multilanguage training was done like that
    output_path=output_path,
    datasets=[dataset_config],
    cudnn_benchmark=False,
    eval_split_max_size=300, # max number of eval samples 
    eval_split_size=0.1, # 10% of the samples to eval
)

# INITIALIZE THE AUDIO PROCESSOR
# Audio processor is used for feature extraction and audio I/O.
# It mainly serves to the dataloader and the training loggers.
ap = AudioProcessor.init_from_config(config)

# INITIALIZE THE TOKENIZER
# Tokenizer is used to convert text to sequences of token IDs.
# config is updated with the default characters if not defined in the config.
tokenizer, config = TTSTokenizer.init_from_config(config)

# LOAD DATA SAMPLES
# Each sample is a list of ```[text, audio_file_path, speaker_name]```
# You can define your custom sample loader returning the list of samples.
# Or define your custom formatter and pass it to the `load_tts_samples`.
# Check `TTS.tts.datasets.load_tts_samples` for more details.
train_samples, eval_samples = load_tts_samples(
    dataset_config,
    eval_split=True,
    eval_split_max_size=config.eval_split_max_size,
    eval_split_size=config.eval_split_size,
)

# init model
model = Vits(config, ap, tokenizer, speaker_manager=None)

# init the trainer and üöÄ
trainer = Trainer(
    TrainerArgs(),
    config,
    output_path,
    model=model,
    train_samples=train_samples,
    eval_samples=eval_samples,
)
trainer.fit()
